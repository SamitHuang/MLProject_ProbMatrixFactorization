{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "K=2\n",
    "lamU=0.1\n",
    "lamV=0.1\n",
    "\n",
    "lr = 0.001 #step size i.e. learning rate\n",
    "MAX_ITER = 10 #200\n",
    "\n",
    "path = \"../dataset/data.npz\"\n",
    "\n",
    "npzfile = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id', 'user_id', 'rating']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data combination and split. implement based on numpy API\n",
    "#\n",
    "dataAll = np.asarray([npzfile['user_id'].reshape(-1), npzfile['item_id'].reshape(-1), npzfile['rating'].reshape(-1)] )\n",
    "dataAll=dataAll.T\n",
    "[USER_ID_MAX, ITEM_ID_MAX, _] = np.max(dataAll, axis=0) #TODO: n unique\n",
    "trainData, testData = train_test_split(dataAll, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R_train = dataToMatrix(trainData)\n",
    "indicator = (R_train > 0).astype(int)\n",
    "np.random.seed(seed=1) # for reproducible\n",
    "#initialize params\n",
    "U= np.random.random_sample((K, USER_ID_MAX))\n",
    "V= np.random.random_sample((K, ITEM_ID_MAX))\n",
    "\n",
    "R_test = dataToMatrix(testData)\n",
    "indicatoR_test = (R_test>0).astype(int)\n",
    "\n",
    "\n",
    "R_pred = U.T @ V # matmul, TODO: logistic function to overcome rating out range\n",
    "diff = indicator * (R_train - R_pred)\n",
    "\n",
    "rmseTrain=[]\n",
    "rmseTest=[]\n",
    "\n",
    "\n",
    "for epoch in range(MAX_ITER):\n",
    "     #TODO: Linear with # of rating. take advantage of the sparsity of the matrix.\n",
    "    dEdU = -V @ diff.T  + lamU * U\n",
    "    dEdV = -U @ diff  + lamV * V\n",
    "    # sync update \n",
    "    Ut = U - lr * dEdU #TODO:  - or +\n",
    "    Vt = V - lr * dEdV\n",
    "    U = Ut\n",
    "    V = Vt\n",
    "    \n",
    "    R_pred = U.T @ V #matmul, TODO: logistic function to overcome rating out range\n",
    "    diff = indicator * (R_train - R_pred)\n",
    "    \n",
    "    # evaluate RMSE loss\n",
    "    rmseTrain.append(np.sqrt( (diff**2).sum()/indicator.sum()))\n",
    "    diffTest = indicatoR_test * (R_test - R_pred)\n",
    "    rmseTest.append(np.sqrt( (diffTest**2).sum()/indicatoR_test.sum()))\n",
    "    print(\"Epoch {}: Train RMSE: {:.4f}\\t Test RMSE: {:.4f}\".format(epoch, rmseTrain[epoch], rmseTest[epoch]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train RMSE: 2.3795\n",
      "Epoch 1: Train RMSE: 1.7711\n",
      "Epoch 2: Train RMSE: 1.4818\n",
      "Epoch 3: Train RMSE: 1.3286\n",
      "Epoch 4: Train RMSE: 1.2330\n",
      "Epoch 5: Train RMSE: 1.1682\n",
      "Epoch 6: Train RMSE: 1.1217\n",
      "Epoch 7: Train RMSE: 1.0870\n",
      "Epoch 8: Train RMSE: 1.0604\n",
      "Epoch 9: Train RMSE: 1.0394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.056744314856704"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training and infer without cross validation\n",
    "# note that idx starts from 0. user_id=1 ->  row 0 in the matrix\n",
    "def dataToMatrix(data, dim=[USER_ID_MAX, ITEM_ID_MAX]):\n",
    "    matrix = np.zeros(dim)\n",
    "    for ins in data:\n",
    "        matrix[ins[0]-1,ins[1]-1] = ins[2]\n",
    "    return matrix\n",
    "\n",
    "#rawData -input data with format [[userId, itemId, rating]xN]\n",
    "def PMF_test(rawData, U, V):\n",
    "    #TODO: use sparsity.\n",
    "    R_test = dataToMatrix(rawData)\n",
    "    indicatoR_test = (R_test>0).astype(int)\n",
    "    R_pred = U.T @ V \n",
    "    diff = indicatoR_test * (R_test - R_pred)\n",
    "    rmse = np.sqrt( (diff**2).sum()/indicatoR_test.sum())\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "#rawData -input data with format [[userId, itemId, rating]xN]\n",
    "#K - the number of latent features\n",
    "def PMF_train(rawData, K=2, maxIter=10, lamU=0.1, lamV=0.1, verbose=False):\n",
    "    R_train = dataToMatrix(rawData)\n",
    "    indicator = (R_train > 0).astype(int)\n",
    "    np.random.seed(seed=1)\n",
    "    #initialize params\n",
    "    U= np.random.random_sample((K, USER_ID_MAX))\n",
    "    V= np.random.random_sample((K, ITEM_ID_MAX))\n",
    "    \n",
    "    R_pred = U.T @ V # matmul, TODO: logistic function to overcome rating out range\n",
    "    diff = indicator * (R_train - R_pred)\n",
    "    \n",
    "    rmseTrain=[]\n",
    "    n_iter = 0\n",
    "    for epoch in range(maxIter):\n",
    "         #TODO: Linear with # of rating. take advantage of the sparsity of the matrix.\n",
    "        dEdU = -V @ diff.T  + lamU * U\n",
    "        dEdV = -U @ diff  + lamV * V\n",
    "        # sync update \n",
    "        Ut = U - lr * dEdU #TODO:  - or +\n",
    "        Vt = V - lr * dEdV\n",
    "        U = Ut\n",
    "        V = Vt\n",
    "\n",
    "        R_pred = U.T @ V #matmul, TODO: logistic function to overcome rating out range\n",
    "        diff = indicator * (R_train - R_pred)\n",
    "        \n",
    "        n_iter +=1\n",
    "        \n",
    "        rmseTrain.append(np.sqrt( (diff**2).sum()/indicator.sum()))\n",
    "        # evaluate RMSE loss\n",
    "        if(verbose):\n",
    "            print(\"Epoch {}: Train RMSE: {:.4f}\".format(epoch, rmseTrain[epoch]))\n",
    "\n",
    "    return U,V, n_iter, rmseTrain[-1]\n",
    "    \n",
    "U,V,n_iter, rmse = PMF_train(trainData,K=3, verbose=True)\n",
    "PMF_test(testData, U, V)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: K=2, rmse=1.1840571665053443\n",
      "Score: K=2, rmse=1.150187272884002\n",
      "Score: K=2, rmse=1.1794908533565276\n",
      "Score: K=2, rmse=1.151004720246238\n",
      "Score: K=2, rmse=1.180255370377696\n",
      "Score: K=2, rmse=1.1506989282373195\n",
      "Score: K=2, rmse=1.1921504184964513\n",
      "Score: K=2, rmse=1.1496392109291786\n",
      "Score: K=2, rmse=1.187056323796341\n",
      "Score: K=2, rmse=1.148932383615149\n",
      "Score: K=3, rmse=1.1144947817230701\n",
      "Score: K=3, rmse=1.085357686281359\n",
      "Score: K=3, rmse=1.1147910040975892\n",
      "Score: K=3, rmse=1.0860304352430905\n",
      "Score: K=3, rmse=1.1150147910813726\n",
      "Score: K=3, rmse=1.0857650569388393\n",
      "Score: K=3, rmse=1.127379658992456\n",
      "Score: K=3, rmse=1.0841440330685876\n"
     ]
    }
   ],
   "source": [
    "class PMF(BaseEstimator,TransformerMixin): #TODO: Transformer needed?\n",
    "    def __init__(self, maxIter=200, K=2, lamU=0.1, lamV=0.1 ):\n",
    "        self.maxIter = maxIter\n",
    "        self.K = K\n",
    "        self.lamU = lamU\n",
    "        self.lamV = lamV\n",
    "        \n",
    "        self.U = np.random.random_sample((K, USER_ID_MAX))\n",
    "        self.V = np.random.random_sample((K, ITEM_ID_MAX))\n",
    "        \n",
    "    \n",
    "    # interface for estimator\n",
    "    def fit(self, X, y=None, **params):\n",
    "        U, V, n_iter_, train_rmse_ = PMF_train(X, K=self.K, lamU=self.lamU, lamV=self.lamV)\n",
    "        \n",
    "        #parameters with trailing _ is used to check if the estimator has been fitted\n",
    "        #TODO: add validation rmse\n",
    "        self.rmse_=  train_rmse_\n",
    "        self.n_iter_ = n_iter_\n",
    "        self.U = U\n",
    "        self.V = V\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    # interface for transformer \n",
    "    def transform(self, X):\n",
    "        #check_is_fitted(self, 'rmse_') #TOBE checked\n",
    "        U, V, n_iter_, train_rmse_ = PMF_train(X)\n",
    "        \n",
    "        return U\n",
    "    \n",
    "    # interface for Grid Search\n",
    "    def score(self, X, y=None):\n",
    "        rmse = PMF_test(X, self.U, self.V)\n",
    "        print(\"Score: K={}, rmse={}\".format(self.K, rmse) )\n",
    "        #since build-in gridsearch pick params by \"the bigger the better\"\n",
    "        return -rmse\n",
    "        \n",
    "    #def predict(self, X):\n",
    "\n",
    "tuned_params = {'K':[2,3]}\n",
    "pmfEst = PMF()\n",
    "#model.fit(trainData)\n",
    "#check_estimator(PMF)\n",
    "gs=GridSearchCV(pmfEst, tuned_params, cv=5)\n",
    "gs.fit(trainData)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'mean_train_score',\n",
       " 'param_K',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split0_train_score',\n",
       " 'split1_test_score',\n",
       " 'split1_train_score',\n",
       " 'split2_test_score',\n",
       " 'split2_train_score',\n",
       " 'split3_test_score',\n",
       " 'split3_train_score',\n",
       " 'split4_test_score',\n",
       " 'split4_train_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score',\n",
       " 'std_train_score']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train RMSE: 2.7059\t Test RMSE: 2.7170\n",
      "Epoch 1: Train RMSE: 2.1115\t Test RMSE: 2.1261\n",
      "Epoch 2: Train RMSE: 1.7169\t Test RMSE: 1.7300\n",
      "Epoch 3: Train RMSE: 1.4985\t Test RMSE: 1.5105\n",
      "Epoch 4: Train RMSE: 1.3645\t Test RMSE: 1.3766\n",
      "Epoch 5: Train RMSE: 1.2731\t Test RMSE: 1.2862\n",
      "Epoch 6: Train RMSE: 1.2072\t Test RMSE: 1.2214\n",
      "Epoch 7: Train RMSE: 1.1577\t Test RMSE: 1.1732\n",
      "Epoch 8: Train RMSE: 1.1197\t Test RMSE: 1.1364\n",
      "Epoch 9: Train RMSE: 1.0897\t Test RMSE: 1.1077\n"
     ]
    }
   ],
   "source": [
    "#linear running time in observed ratings. using the sparsity\n",
    "np.random.seed(seed=1)\n",
    "U= np.random.random_sample((K, USER_ID_MAX))\n",
    "V= np.random.random_sample((K, ITEM_ID_MAX))\n",
    "MAX_ITER2=2\n",
    "for epoch in range(MAX_ITER2):\n",
    "    # linear algo. Batch Gradient Descent\n",
    "    Ut = U\n",
    "    Vt = V\n",
    "    for (userID,itemID,rij) in trainData:\n",
    "        i = userID - 1\n",
    "        j = itemID - 1\n",
    "        rij_pred = np.dot((U.T)[i,:],V[:,j])\n",
    "        diff_ij = rij - rij_pred\n",
    "        #partially update the latent features of user i and item j\n",
    "        Ut[:,i] += - lr * (-V[:,j] * diff_ij) \n",
    "        Vt[:,j] += - lr * (-U[:,i] * diff_ij)\n",
    "        \n",
    "        #rmseTrain[epoch] += diff_ij**2\n",
    "    #update U and V\n",
    "    Ut = Ut - lr * ( lamU * U)\n",
    "    Vt = Vt - lr * (lamV * V)\n",
    "    U = Ut\n",
    "    V = Vt\n",
    "    \n",
    "    #evaluate\n",
    "    #rmseTrain[epoch] = np.sqrt(rmseTrain[epoch]/len(trainData))\n",
    "    R_pred = U.T @ V\n",
    "    diffTrain = indicator * (R_train - R_pred)\n",
    "    rmseTrain[epoch] = np.sqrt( (diffTrain**2).sum()/indicator.sum())\n",
    "    diffTest = indicatoR_test * (R_test - R_pred)\n",
    "    rmseTest[epoch] = np.sqrt( (diffTest**2).sum()/indicatoR_test.sum())\n",
    "    print(\"Epoch {}: Train RMSE: {:.4f}\\t Test RMSE: {:.4f}\".format(epoch, rmseTrain[epoch], rmseTest[epoch]))\n",
    "    \n",
    "###===> The running time is longer than that of using the complete matrix    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning params with cross-validation and grid-search, based on sklearn BaseEstimator\n",
    "len(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "(2, 1682)\n",
      "(2, 943)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for python test\n",
    "np.random.seed(seed=1)\n",
    "a = np.random.random_sample((2,2))\n",
    "b = (a > 0).astype(int)\n",
    "b[0,0]=0\n",
    "print(RMatrix.shape)\n",
    "print(V.shape)\n",
    "print(U.shape)\n",
    "dt=np.asarray([1,1])\n",
    "indicator.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
