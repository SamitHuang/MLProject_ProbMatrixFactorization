{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "path = \"../dataset/data.npz\"\n",
    "\n",
    "npzfile = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id', 'user_id', 'rating']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[242]\n",
      " [302]\n",
      " [377]\n",
      " [ 51]\n",
      " [346]\n",
      " [474]\n",
      " [265]\n",
      " [465]\n",
      " [451]\n",
      " [ 86]]\n",
      "[[196]\n",
      " [186]\n",
      " [ 22]\n",
      " [244]\n",
      " [166]\n",
      " [298]\n",
      " [115]\n",
      " [253]\n",
      " [305]\n",
      " [  6]]\n"
     ]
    }
   ],
   "source": [
    "#reshape the npzfile and split the dataset\n",
    "item_id = npzfile['item_id'][0:10]\n",
    "user_id = npzfile['user_id'][0:10]\n",
    "item_id_train, item_id_test,user_id_train, user_id_test = train_test_split(item_id,user_id, test_size=0.2, random_state = 1)\n",
    "print(item_id)\n",
    "print(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data combination and split. implement from first principle\n",
    "data = []\n",
    "for i in range(10):\n",
    "    data.append([npzfile[\"user_id\"][i][0],npzfile['item_id'][i][0], npzfile['rating'][i][0]])\n",
    "data = np.asarray(data, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data combination and split. implement based on numpy API\n",
    "#\n",
    "dataAll = np.asarray([npzfile['user_id'].reshape(-1), npzfile['item_id'].reshape(-1), npzfile['rating'].reshape(-1)] )\n",
    "dataAll=dataAll.T\n",
    "[USER_ID_MAX, ITEM_ID_MAX, _] = np.max(dataAll, axis=0) #TODO: n unique\n",
    "trainData, testData = train_test_split(dataAll, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train RMSE: 2.7541\t Test RMSE: 2.7649\n",
      "Epoch 1: Train RMSE: 2.1329\t Test RMSE: 2.1473\n",
      "Epoch 2: Train RMSE: 1.7141\t Test RMSE: 1.7247\n",
      "Epoch 3: Train RMSE: 1.4961\t Test RMSE: 1.5070\n",
      "Epoch 4: Train RMSE: 1.3596\t Test RMSE: 1.3713\n",
      "Epoch 5: Train RMSE: 1.2672\t Test RMSE: 1.2800\n",
      "Epoch 6: Train RMSE: 1.2012\t Test RMSE: 1.2152\n",
      "Epoch 7: Train RMSE: 1.1521\t Test RMSE: 1.1674\n",
      "Epoch 8: Train RMSE: 1.1145\t Test RMSE: 1.1311\n",
      "Epoch 9: Train RMSE: 1.0850\t Test RMSE: 1.1029\n"
     ]
    }
   ],
   "source": [
    "#training and infer without cross validation\n",
    "\n",
    "K=2\n",
    "lamU=0.1\n",
    "lamV=0.1\n",
    "\n",
    "lr = 0.001 #step size i.e. learning rate\n",
    "MAX_ITER = 10 #200\n",
    "\n",
    "# note that idx starts from 0. user_id=1 ->  row 0 in the matrix\n",
    "def dataToMatrix(data, dim=[USER_ID_MAX, ITEM_ID_MAX]):\n",
    "    matrix = np.zeros(dim)\n",
    "    for ins in data:\n",
    "        matrix[ins[0]-1,ins[1]-1] = ins[2]\n",
    "    return matrix\n",
    "\n",
    "R_train = dataToMatrix(trainData)\n",
    "indicator = (R_train > 0).astype(int)\n",
    "np.random.seed(seed=1) # for reproducible\n",
    "#initialize params\n",
    "U= np.random.random_sample((K, USER_ID_MAX))\n",
    "V= np.random.random_sample((K, ITEM_ID_MAX))\n",
    "\n",
    "R_test = dataToMatrix(testData)\n",
    "indicatoR_test = (R_test>0).astype(int)\n",
    "\n",
    "\n",
    "R_pred = U.T @ V # matmul, TODO: logistic function to overcome rating out range\n",
    "diff = indicator * (R_train - R_pred)\n",
    "\n",
    "rmseTrain=[]\n",
    "rmseTest=[]\n",
    "\n",
    "\n",
    "for epoch in range(MAX_ITER):\n",
    "     #TODO: Linear with # of rating. take advantage of the sparsity of the matrix.\n",
    "    dEdU = -V @ diff.T  + lamU * U\n",
    "    dEdV = -U @ diff  + lamV * V\n",
    "    # sync update \n",
    "    Ut = U - lr * dEdU #TODO:  - or +\n",
    "    Vt = V - lr * dEdV\n",
    "    U = Ut\n",
    "    V = Vt\n",
    "    \n",
    "    R_pred = U.T @ V #matmul, TODO: logistic function to overcome rating out range\n",
    "    diff = indicator * (R_train - R_pred)\n",
    "    \n",
    "    # evaluate RMSE loss\n",
    "    rmseTrain.append(np.sqrt( (diff**2).sum()/indicator.sum()))\n",
    "    diffTest = indicatoR_test * (R_test - R_pred)\n",
    "    rmseTest.append(np.sqrt( (diffTest**2).sum()/indicatoR_test.sum()))\n",
    "    print(\"Epoch {}: Train RMSE: {:.4f}\\t Test RMSE: {:.4f}\".format(epoch, rmseTrain[epoch], rmseTest[epoch]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train RMSE: 2.7059\t Test RMSE: 2.7170\n",
      "Epoch 1: Train RMSE: 2.1115\t Test RMSE: 2.1261\n",
      "Epoch 2: Train RMSE: 1.7169\t Test RMSE: 1.7300\n",
      "Epoch 3: Train RMSE: 1.4985\t Test RMSE: 1.5105\n",
      "Epoch 4: Train RMSE: 1.3645\t Test RMSE: 1.3766\n",
      "Epoch 5: Train RMSE: 1.2731\t Test RMSE: 1.2862\n",
      "Epoch 6: Train RMSE: 1.2072\t Test RMSE: 1.2214\n",
      "Epoch 7: Train RMSE: 1.1577\t Test RMSE: 1.1732\n",
      "Epoch 8: Train RMSE: 1.1197\t Test RMSE: 1.1364\n",
      "Epoch 9: Train RMSE: 1.0897\t Test RMSE: 1.1077\n"
     ]
    }
   ],
   "source": [
    "#linear running time in observed ratings. using the sparsity\n",
    "np.random.seed(seed=1)\n",
    "U= np.random.random_sample((K, USER_ID_MAX))\n",
    "V= np.random.random_sample((K, ITEM_ID_MAX))\n",
    "\n",
    "for epoch in range(MAX_ITER):\n",
    "    # linear algo. Batch Gradient Descent\n",
    "    Ut = U\n",
    "    Vt = V\n",
    "    for (userID,itemID,rij) in trainData:\n",
    "        i = userID - 1\n",
    "        j = itemID - 1\n",
    "        rij_pred = np.dot((U.T)[i,:],V[:,j])\n",
    "        diff_ij = rij - rij_pred\n",
    "        #partially update the latent features of user i and item j\n",
    "        Ut[:,i] += - lr * (-V[:,j] * diff_ij) \n",
    "        Vt[:,j] += - lr * (-U[:,i] * diff_ij)\n",
    "        \n",
    "        #rmseTrain[epoch] += diff_ij**2\n",
    "    #update U and V\n",
    "    Ut = Ut - lr * ( lamU * U)\n",
    "    Vt = Vt - lr * (lamV * V)\n",
    "    U = Ut\n",
    "    V = Vt\n",
    "    \n",
    "    #evaluate\n",
    "    #rmseTrain[epoch] = np.sqrt(rmseTrain[epoch]/len(trainData))\n",
    "    R_pred = U.T @ V\n",
    "    diffTrain = indicator * (R_train - R_pred)\n",
    "    rmseTrain[epoch] = np.sqrt( (diffTrain**2).sum()/indicator.sum())\n",
    "    diffTest = indicatoR_test * (R_test - R_pred)\n",
    "    rmseTest[epoch] = np.sqrt( (diffTest**2).sum()/indicatoR_test.sum())\n",
    "    print(\"Epoch {}: Train RMSE: {:.4f}\\t Test RMSE: {:.4f}\".format(epoch, rmseTrain[epoch], rmseTest[epoch]))\n",
    "    \n",
    "###===> The running time is longer than that of using the complete matrix    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tuning params with cross-validation and grid-search, based on sklearn BaseEstimator\n",
    "len(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682)\n",
      "(2, 1682)\n",
      "(2, 943)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for python test\n",
    "np.random.seed(seed=1)\n",
    "a = np.random.random_sample((2,2))\n",
    "b = (a > 0).astype(int)\n",
    "b[0,0]=0\n",
    "print(RMatrix.shape)\n",
    "print(V.shape)\n",
    "print(U.shape)\n",
    "dt=np.asarray([1,1])\n",
    "indicator.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
